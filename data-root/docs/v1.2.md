# DOCUMENTAÇÃO
**COMPONENTES:** Victor Bittencourt, Nestor Preissler, Erika Maschio, Matheus Neves e Bruno Kaue.  
**FERRAMENTAS-CHAVE:** Python, Jupyter Notebook, Pandas, Numpy, Seaborn, Scikit-Learn, Plotly e Matplotlib.

## S03T05: Criar Novas Features Relevantes para o Problema
[Realizado, porém passível de mudança]

## S04T01: Dividir os Conjuntos de Teste/Treino
Após testes de distribuição a melhor forma de distribuir nos conjuntos encontrada foi: como 60% treino e 40% teste. O que possibilitou um resultado final perceptivelmente bom em outras tarefas desempenhadas a partir disso. 

## S04T02: Documentar Estratégia de Divisão
A divisão dos dados de teste e treino foi baseada nas features criadas e nas colunas que deviam ser utilizadas nas métricas de avaliação do modelo, levando em consideração o seguinte:
- Não se pode treinar com valores em excesso (overfitting), para evitar problemas de viés nas previsões;
- Não se pode treinar com outliers, para evitar viés de peso das classes;

No processo de divisão, foi escolhida a seguinte aproximação, um modelo 60/40 para evitar overfitting e também estimular o modelo a lidar com as mudanças, sendo mais flexível a possíveis valores diferentes devido a não se basear especificamente nos conhecimentos únicos daquele dataset.

Foram utilizados dois modelos:
    RandomForestClassifier
    KNeighborsClassifier

Ambos tiveram a mesma divisão, assim como a mesma "aleatoriedade".

## S04T03: 
A tarefa em questão foi realizada com exito tendo resultados extremamente favoráveis quanto a treino, tendo precisão de 0.94 e acurácia de 0.9375, o que  afirma que o modelo se saiu bem em treino. 

## S04T04
 O modelo foi escolhido conforme uma "pesquisa" através da função GridSearchCV do sklearn que apresentou o melhor modelo para a resolução do problema apresentado pela empresa PsyCaldeira.
  
Melhores hiperparâmetros encontrados no RandomForestClassifier: 'n_estimators': 100,  'max_depth': 7, 'min_samples_leaf': 4
Melhores hiperparâmetros encontrados no KNeighborsClassifier: 'leaf_size': 50, 'n_jobs': None, 'n_neighbors': 5

Avaliação do modelo RandomForest: Acurácia próxima a 94%, precisão MACRO de 83% e recall MACRO de 92% são alguns dos retornos extremamente satisfatórios que o modelo apresentou em avaliações. Percepção de casos de depressão foi de 68%.
Avaliação do modelo KNeighbors: Acurácia próxima a 90%, precisão MACRO de 80% e recall MACRO de 82% são retornos bem satisfatórios que o modelo apresentou em avaliações. Percepção dos casos de depressão foi 65%.

Comparação de acurácia entre os modelos:
- 90% de acurácia dos resultados semelhantes;

Interpretação dos Resultados: [Bruno]

Conclusões e Próximos Passos: [Bruno]