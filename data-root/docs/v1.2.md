# DOCUMENTAÇÃO
**COMPONENTES:** Victor Bittencourt, Nestor Preissler, Erika Maschio, Matheus Neves e Bruno Kaue.  
**FERRAMENTAS-CHAVE:** Python, Jupyter Notebook, Pandas, Numpy, Seaborn, Scikit-Learn, Plotly e Matplotlib.

## S03T05: Criar Novas Features Relevantes para o Problema
[Realizado, porém passível de mudança]

## S04T01: Dividir os Conjuntos de Teste/Treino
Após testes de distribuição a melhor forma de distribuir nos conjuntos encontrada foi: como 60% treino e 40% teste. O que possibilitou um resultado final perceptivelmente bom em outras tarefas desempenhadas a partir disso. 

## S04T02: Documentar Estratégia de Divisão
A divisão dos dados de teste e treino foi baseada nas features criadas e nas colunas que deviam ser utilizadas nas métricas de avaliação do modelo, levando em consideração o seguinte:
- Não se pode treinar com valores em excesso (overfitting), para evitar problemas de viés nas previsões;
- Não se pode treinar com outliers, para evitar viés de peso das classes;

No processo de divisão, foi escolhida a seguinte aproximação, um modelo 60/40 para evitar overfitting e também estimular o modelo a lidar com as mudanças, sendo mais flexível a possíveis valores diferentes devido a não se basear especificamente nos conhecimentos únicos daquele dataset.

Foram utilizados dois modelos:
    RandomForestClassifier
    KNeighborsClassifier

Ambos tiveram a mesma divisão, assim como a mesma "aleatoriedade".

## S04T03: 
A tarefa em questão foi realizada com exito tendo resultados extremamente favoráveis quanto a treino, tendo precisão de 0.94 e acurácia de 0.9375, o que  afirma que o modelo se saiu bem em treino. 

## S04T04
 O modelo foi escolhido conforme uma "pesquisa" através da função GridSearchCV do sklearn que apresentou o melhor modelo para a resolução do problema apresentado pela empresa PsyCaldeira.
  
Melhores hiperparâmetros encontrados no RandomForestClassifier: 'n_estimators': 100,  'max_depth': 7, 'min_samples_leaf': 4
Melhores hiperparâmetros encontrados no KNeighborsClassifier: 'leaf_size': 50, 'n_jobs': None, 'n_neighbors': 5

Avaliação do modelo RandomForest: Acurácia próxima a 94%, precisão MACRO de 83% e recall MACRO de 92% são alguns dos retornos extremamente satisfatórios que o modelo apresentou em avaliações. Percepção de casos de depressão foi de 68%.
Avaliação do modelo KNeighbors: Acurácia próxima a 90%, precisão MACRO de 80% e recall MACRO de 82% são retornos bem satisfatórios que o modelo apresentou em avaliações. Percepção dos casos de depressão foi 65%.

Comparação de acurácia entre os modelos:
- 90% de acurácia dos resultados semelhantes;

Interpretação dos Resultados:
Acurácia 94%: Significa que o modelo classificou cerca de 94% das instancias. A acurácia alta é um bom indicativo geral, mas é importante verificar se as classes estão balanceadas, caso não estejam, os resultados podem ser enganosos, favorecendo a classe majoritária.

Precisão 94%: Dos exemplos classificados como positivos, 94% dos exmplos realmente pertencem a classe positiva. A alta precisão sugere que o modelo tem poucos falsos positivos, ou seja, ele raramente classifica como positivo quando não deveria. Isso é crucial em cenários onde falsos positivos são custosos, como diagnósticos médicos ou detecção de fraudes.


Recall 99%: O modelo conseguiu identificar 99% dos exemplos que pertencem à classe positiva. Um recall elevado indica que o modelo possui poucos falsos negativos, sendo muito eficaz em capturar quase todos os exemplos da classe positiva. Isso é especialmente importante quando a prioridade é minimizar falsos negativos.

Conclusões e Próximos Passos: Considerando o excelente desempenho do modelo, com um recall elevado de 99%, o próximo passo será realizar testes com dados reais ou em ambiente simulado. Isso nos permitirá validar seu comportamento em situações do mundo real, identificar possíveis discrepâncias e garantir que continue minimizando falsos negativos de forma consistente, mantendo sua robustez e confiabilidade com novos dados.