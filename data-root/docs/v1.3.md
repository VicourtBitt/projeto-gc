# DOCUMENTAÇÃO
**COMPONENTES:** Victor Bittencourt, Nestor Preissler, Erika Maschio, Matheus Neves e Bruno Kaue.  
**FERRAMENTAS-CHAVE:** Python, Jupyter Notebook, Pandas, Numpy, Seaborn, Scikit-Learn, Plotly e Matplotlib.

## S01T01: Pesquisar um Dataset
Durante o processo de seleção do dataset para o desenvolvimento do projeto, fomos avaliando diversas opções, que iam desde métricas financeiras até análises agronômicas, porém, contudo, escolhemos um dataset que abordava pesquisas sobre índices de depressão relacionados aos padrões de vida dos indivíduos.

**DATASET:** [https://www.kaggle.com/datasets/sumansharmadataworld/depression-surveydataset-for-analysis/data](https://www.kaggle.com/datasets/sumansharmadataworld/depression-surveydataset-for-analysis/data)

## S01T02: Descrição/Cenário/Objetivo
A definição do problema girou ao redor da seguinte narrativa:
“O PsyCaldeira, empresa (fictícia) que trabalha com tratamentos psicoterapêuticos e análise de índices de doenças psicológicas/neurodivergentes reportou baseado em uma suposição o aumento de possíveis casos de depressão e necessita de algum sistema que possa auxiliar a detecção e tratamento de dados categóricos em excesso baseado na arquitetura de armazenamento desses dados.”

Com isto em mente, cenário em questão (assim como o objetivo) iriam orbitar a necessidade de auxiliar no processo de detecção dos possíveis pacientes que se enquadram no perfil de pessoa com depressão e demonstrar um sistema efetivo/utilizável.

## S01T03: Versionar dataset e documentação
Sobre versionamento de código/dataset, o time preferiu uma aproximação mais tradicional quanto ao versionamento, onde existem 3 (três) branches principais, a main (ou branch raiz), a dev (branch de desenvolvimento) e as features (branches em que se adicionam funcionalidades ou se mostram novos progressos no desenvolvimento individual), o fluxo de imagem (entrada) se explica com facilidade seguindo o “diagrama” a seguir:  
main > dev > feature  
Neste caso, a imagem base é a main, da qual a dev vem a derivar e por último, as features se ramificam da dev.

Agora, quanto ao fluxo de atualização (saída), dá para explicar da seguinte forma:  
feature > dev > [PR] > main  
Nessa representação, a feature é a imagem base, da qual entra para dev por meio de um [PR] (Pull Request), para aí então ser aceita na main. No meio do processo “feature>dev” também existe um [PR], porém ele tem menor peso do que o [PR] “dev/main”.

Quanto à documentação, abrangiremos um fluxo de documentação “entre-tasks”, assim como também serão resumidos os acontecimentos como um todo.

## S02T01: Cálculos Estatístico Descritivos
[Bruno Kaue…] – não completo até o momento

## S02T02: Visualização Básica Gráfica
[Matheus Neves…] – não completo até o momento

## S02T03: Identificação e Tratamento de Dados Faltantes
Durante o processo de desenvolvimento, surgiram algumas observações quanto à análise inicial do dataset, haviam dados faltantes em colunas “context-relative”, assim como haviam informações faltantes por não-inputação. Sobre as colunas CR (“context-relative”) foi realizada a seguinte aproximação:

- **academic/work_pressure/satisfaction:** estas colunas eram complementares, por exemplo, quando o indivíduo possuía valores em academic (estudante) faltavam valores nas colunas work (trabalhador) e vice-versa, estes casos foram tratados por meio da criação de uma coluna intermediária, chamada “general_satisfaction/pressure”. O que evidentemente satisfazia a relação momentânea estudo/trabalho.
- **CGPA:** esta coluna representava o conceito médio acadêmico, faltando 86% das linhas presentes. A mesma foi retirada.

Após isto, foram analisadas as colunas com poucos valores faltantes, sendo ela a de profissão, da qual, por decisão comum, os valores faltantes seriam preenchidos com “Unemployed” para representar um possível desempregado.

## S02T04: Identificar e Tratar Outliers
Na tarefa citada em questão, foi possível notar após a exibição de alguns gráficos que o dataframe no seu estado completamente limpo e normalizado não contém nenhum outlier (notável) em quaisquer uma das colunas.

## S02T05: Gerar Relatório Inicial com Insights
[Bruno Kaue…] – não completo até o momento

## S03T01: Remover Duplicatas ou Inconsistências
Assim como na S02T03, aqui foi realizada a remoção de valores duplicados ou inconsistentes, o que pode ser definido por exemplo como: cidades, nome, nota acadêmica e os mesmos valores de relação estudo-trabalho.

## S03T02: Normalizar ou Padronizar Colunas
Ambos os processos de tratamento para futura aplicação a modelos de aprendizado de máquina foram realizados focando na padronalização dos valores, assim também como, na normalização. Colunas que podiam ser metrificadas como ‘dieta’, ou colunas categóricas como ‘está trabalhando’/’familiares com histórico psiquiátrico’ foram tratadas das devidas maneiras.

## S03T03: Transformar Variáveis Categóricas em Numéricas
Semelhante à entrega S03T02, realizamos os devidos tratamentos para evitar comparações de texto e permitir um maior entendimento ao modelo.

## S03T04: Não definida
Não temos.

## S03T05: Criar Novas Features Relevantes para o Problema
[Realizado, porém passível de mudança]

## S04T01: Dividir os Conjuntos de Teste/Treino
Após testes de distribuição a melhor forma de distribuir nos conjuntos encontrada foi: como 60% treino e 40% teste. O que possibilitou um resultado final perceptivelmente bom em outras tarefas desempenhadas a partir disso. 

## S04T02: Documentar Estratégia de Divisão
A divisão dos dados de teste e treino foi baseada nas features criadas e nas colunas que deviam ser utilizadas nas métricas de avaliação do modelo, levando em consideração o seguinte:
- Não se pode treinar com valores em excesso (overfitting), para evitar problemas de viés nas previsões;
- Não se pode treinar com outliers, para evitar viés de peso das classes;

No processo de divisão, foi escolhida a seguinte aproximação, um modelo 60/40 para evitar overfitting e também estimular o modelo a lidar com as mudanças, sendo mais flexível a possíveis valores diferentes devido a não se basear especificamente nos conhecimentos únicos daquele dataset.

Foram utilizados dois modelos:
    RandomForestClassifier
    KNeighborsClassifier

Ambos tiveram a mesma divisão, assim como a mesma "aleatoriedade".

## S04T03: 
A tarefa em questão foi realizada com exito tendo resultados extremamente favoráveis quanto a treino, tendo precisão de 0.94 e acurácia de 0.9375, o que  afirma que o modelo se saiu bem em treino. 

## S04T04
 O modelo foi escolhido conforme uma "pesquisa" através da função GridSearchCV do sklearn que apresentou o melhor modelo para a resolução do problema apresentado pela empresa PsyCaldeira.
  
Melhores hiperparâmetros encontrados no RandomForestClassifier: 'n_estimators': 100,  'max_depth': 7, 'min_samples_leaf': 4
Melhores hiperparâmetros encontrados no KNeighborsClassifier: 'leaf_size': 50, 'n_jobs': None, 'n_neighbors': 5

Avaliação do modelo RandomForest: Acurácia próxima a 94%, precisão MACRO de 83% e recall MACRO de 92% são alguns dos retornos extremamente satisfatórios que o modelo apresentou em avaliações. Percepção de casos de depressão foi de 68%.
Avaliação do modelo KNeighbors: Acurácia próxima a 90%, precisão MACRO de 80% e recall MACRO de 82% são retornos bem satisfatórios que o modelo apresentou em avaliações. Percepção dos casos de depressão foi 65%.

Comparação de acurácia entre os modelos:
- 90% de acurácia dos resultados semelhantes;

Interpretação dos Resultados:
Acurácia 94%: Significa que o modelo classificou cerca de 94% das instancias. A acurácia alta é um bom indicativo geral, mas é importante verificar se as classes estão balanceadas, caso não estejam, os resultados podem ser enganosos, favorecendo a classe majoritária.

Precisão 94%: Dos exemplos classificados como positivos, 94% dos exmplos realmente pertencem a classe positiva. A alta precisão sugere que o modelo tem poucos falsos positivos, ou seja, ele raramente classifica como positivo quando não deveria. Isso é crucial em cenários onde falsos positivos são custosos, como diagnósticos médicos ou detecção de fraudes.


Recall 99%: O modelo conseguiu identificar 99% dos exemplos que pertencem à classe positiva. Um recall elevado indica que o modelo possui poucos falsos negativos, sendo muito eficaz em capturar quase todos os exemplos da classe positiva. Isso é especialmente importante quando a prioridade é minimizar falsos negativos.

Conclusões e Próximos Passos: Considerando o excelente desempenho do modelo, com um recall elevado de 99%, o próximo passo será realizar testes com dados reais ou em ambiente simulado. Isso nos permitirá validar seu comportamento em situações do mundo real, identificar possíveis discrepâncias e garantir que continue minimizando falsos negativos de forma consistente, mantendo sua robustez e confiabilidade com novos dados.

## Conclusão:

Com base nos resultados obtidos durante o desenvolvimento deste projeto de machine learning, concluímos que os modelos RandomForestClassifier e KNeighborsClassifier apresentaram desempenhos satisfatórios em termos de acurácia, precisão e recall. O RandomForestClassifier, em particular, destacou-se com uma acurácia próxima a 94%, precisão de 94%, e um recall de 99%, o que indica sua robustez na detecção de casos de depressão com pouquíssimos falsos negativos.

Esses resultados são promissores e sugerem que o modelo está bem preparado para ser testado em ambientes mais complexos e variados. A alta precisão e recall indicam que o modelo é confiável tanto para identificar corretamente os casos de depressão quanto para minimizar os erros de classificação.

#### Próximos Passos:

Monitoramento Contínuo: Estabelecer um sistema de monitoramento para avaliar continuamente o desempenho do modelo em produção. Isso garantirá que o modelo se adapte bem a novas informações e mantenha sua eficácia ao longo do tempo.

Refinamento do Modelo: Com base no feedback dos testes com dados reais, realizar ajustes nos hiperparâmetros e na estrutura do modelo, se necessário, para melhorar ainda mais sua precisão e robustez.

Documentação e Treinamento: Garantir que toda a equipe da PsyCaldeira esteja bem informada sobre o funcionamento do modelo e como interpretar seus resultados. Fornecer treinamentos adequados para maximizar a utilidade prática do sistema de detecção de depressão.

Exploração de Novas Features: Continuar a explorar e adicionar novas features relevantes que possam aumentar ainda mais a precisão e o recall do modelo, considerando as mudanças nos dados e padrões emergentes.

Feedback do Usuário: Coletar feedback dos psicoterapeutas e outros usuários finais para identificar possíveis melhorias na interface e na usabilidade do sistema.

## Considerações Finais
O desenvolvimento deste projeto mostrou-se eficaz na criação de um sistema automatizado para a detecção de depressão com alta acurácia e confiabilidade. Através de uma abordagem cuidadosa de seleção de dados, tratamento de inconsistências e escolha de modelos, conseguimos construir uma solução que não apenas atende às necessidades da PsyCaldeira, mas também tem o potencial de impactar positivamente a vida dos pacientes ao permitir uma detecção precoce e precisa da depressão.

Dessa forma, estamos confiantes de que, com os próximos passos definidos, o sistema será uma ferramenta valiosa para a PsyCaldeira e contribuirá significativamente para a melhoria dos serviços oferecidos pela empresa.






